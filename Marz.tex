\documentclass[iop]{emulateapj}
\usepackage{graphicx,hyperref,natbib}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\graphicspath{{figures/}}
\usepackage{amsmath}
\newcommand{\blue}{\color{blue}}
\newcommand{\tam}{\color{blue}}
\newcommand{\tamcom}{\color{red}}
\newcommand{\red}{\color{red}}
\newcommand{\orange}{\color{orange}}
\newcommand{\purple}{\color{purple}}
\newcommand{\green}{\color{LimeGreen}}
\newcommand{\myemail}{samuelreay@gmail.com}
\newcommand{\runz}{\textsc{runz}}
\newcommand{\autoz}{\textsc{autoz}}
\newcommand{\marz}{\textsc{Marz}}

\shorttitle{Manual and Automatic Redshifting Software}
\shortauthors{S. R. Hinton et al.}


\begin{document}

\title{\marz{}: Manual and Automatic Redshifting Software}

\author{S. R. Hinton\altaffilmark{1,2}}
\author{T. M. Davis\altaffilmark{1,2}}
\author{C. Lidman\altaffilmark{2,3}}
\author{K. Glazebrook\altaffilmark{4}}
\author{G. F. Lewis\altaffilmark{5}}
\altaffiltext{1}{Department of Physics, The University of Queensland, Brisbane, QLD 4072, Australia}
\altaffiltext{2}{ARC Centre of Excellence for All-sky Astrophysics (CAASTRO)}
\altaffiltext{3}{Australian Astronomical Observatory, North Ryde, NSW 2113, Australia}
\altaffiltext{4}{Centre for Astrophysics and Supercomputing, Swinburne, University of Technology, Hawthorn, VIC 3122, Australia}
\altaffiltext{5}{Sydney Institute for Astronomy, School of Physics, A28, The University of Sydney, NSW, 2006, Australia}

\begin{abstract}
The Australian Dark Energy Survey (OzDES) is a 100-night spectroscopic survey underway on the Anglo-Australian Telescope using the fibre-fed 2-degree-field (2dF) spectrograph.  We have developed a new redshifting application \marz{} with greater usability, flexibility, and the capacity to analyse a wider range of object types than the \runz{} software package previously used for redshifting spectra from 2dF. \marz{} is an open-source, client-based, Javascript web-application which provides an intuitive interface and powerful automatic matching capabilities on spectra generated from the AAOmega spectrograph to produce high quality spectroscopic measurements. The software is easily adaptable to other instruments and pipelines if conforming to the current FITS file standard is not possible. Behind the scenes, a cross-correlation algorithm is used to match input spectra against a variety of stellar and galactic templates, and automatic matching performance for OzDES spectra has increased from 54\% (\runz{}) to 91\% (\marz{}). Spectra not matched correctly by the automatic algorithm can be easily redshifted manually by cycling automatic results, manual template comparison, or marking spectral features.
\end{abstract}

\section{Introduction}

The Australian arm of the Dark Energy Survey (OzDES) is a five-year, 100-night spectroscopic survey using the Anglo-Australia Telescope (AAT), and aims to provide accurate spectroscopic redshifts of Type Ia supernova hosts, photo-z targets, emission line galaxies (EML) and radio galaxies between redshift ranges of $0.1 \leq  z \leq 1.2$, in addition to spectroscopic measurements of active galactic nuclei and quasars in the redshift range of $0.3 \leq z \leq 4.5$ \cite{fang2015}. A close collaborator with OzDES is the newly formed 2dFLenS survey \footnote{\url{http://astronomy.swin.edu.au/~cblake/2dflens_proposal.pdf}} which aims to measure redshift-space distortion over 985 square degrees in its 50-night spectroscopic survey using with AAT.  The process of extracting redshifts from spectroscopic measurements is thus required to be robust across a wide variety of target types, and since our aim is primarily to acquire redshifts,  our survey will be most efficient when we can extract redshifts from low signal-to-noise spectra.


\section{Prior Software}

A variety of redshifting solutions have been previously developed, with much of the developed software being spectrograph or survey specific. A large amount of prior redshifting software is descendent from the cross correlation algorithms implemented by \citet{tonry1979survey}, in which they digitalised the analog techniques used by \citet{griffin1967photoelectric}. The popular RVSAO 2.0 software package utilises these techniques, in addition to providing feature matching capacity \citep{kurtz1998rvsao}. Unfortunately, the software perating only in command line and without any interactive user input, the 2010 release of the \verb+xcsao+ program (the cross correlation matching algorithm in RSVAO 2.0) takes up to 67 input parameters \citep{parameters}, making intuitive use of the program impossible and introducing experience based technical overhead to cosmology groups attempting to use the software.\\

As of the eighth data release (DR8) of the Sloan Digital Sky Survey (SDSS), the redshifting software used in their survey utilises a minimum $\chi^2$ algorithm \citep{aihara2011eighth}. Prior to DR8, a cross correlation algorithm was used  \citep{sdss6}, where the same results were found when matching using the different methods for 98\% of spectra \cite{aihara2011eighth}. This potential software system also does not satisfy desired usability criteria.\\


\runz{} was written for use by the 2dF galaxy redshift survey \citep{colless2001}, and the OzDES team has previously relied on a version of the \runz{} software package modified by \citet{saunders2004} for use in the WiggleZ survey. It is primarily against this modified version of \runz{} that we compare results to in this report.  Unfortunately, there are several reasons why neither the \runz{} software package, nor other available redshifting software packages, were sufficient for use in the OzDES survey. The foremost problem with using the existing software solution was the inclusion of more varied target object types at a lower signal-to-noise ratio than prior surveys, and the resulting decrease in automatic matching capacity by the legacy software created an unsustainable workload for the members of the OzDES team to manually redshift observed spectra. Additionally, the legacy nature (fortran, pgplot and cshell) of the \runz{} code base makes code updates difficult, installation and usage overly complicated for members of the team and especially difficult for new members to compile, install and learn. The sum of these factors prompted the development of a modern software replacement.\\

It is from the above motivation that a set of minimum requirements were drawn up for the proposed software project. First and foremost, the automatic matching capacity had to exceed that of \runz{}, and the software would have to present an intuitive interface to allow fast manual checking and correction by the user. In regards to basic usability, requirements were for the software to be easy to install, operating system independent, and able to update itself without user prompting. 



\section{Platform}

The choice of utilising a browser platform by implementing the matching software as a web application allows access to the software from any laptop or desktop with an internet connection. The interface utilises Google's AngularJS\footnote{\url{https://angularjs.org/}} framework for its application scaffold, as AngularJS allows dynamic two-way binding between interface and application variables, easy server communication, and has a vast amount of existing resources publicly available.\\

To supplement AngularJS and allow rapid prototyping, existing interface element libraries were imported to reduce the amount of reimplementation of common elements and boilerplate code required to produce a functioning application. To this end, Angular UI's Bootstrap\footnote{\url{https://angular-ui.github.io/bootstrap/}} reimplementation of Twitter's Bootstrap \footnote{\url{http://getbootstrap.com/2.3.2/}} components was added to the project code base.\\

Data processing in browsers has only recently become possible due to HTML5's Web Worker API\footnote{\url{https://html.spec.whatwg.org/multipage/workers.html}}, which allows for multi-threaded processing by sending tasks to independent workers. Communication to Web Workers and any future potential server communication will use JSON (JavaScript Object Notation) format \citep{bray2014javascript}, and will conform to the REST (Representational State Transfer) interface \citep{windley11rest}. This has the benefit of making all messages human-readable and and able to be linked to web services easily due to existing support in all modern server frameworks.\\


Local application state is preserved via utilisation of local storage, where local state is preserved in JSON format. This gives the benefit that results are not lost when exiting the application or refreshing the browser, negating one of the major disadvantages of stateful web applications. Changes to application are persisted via setting cookie properties instead of using local storage, so to provide a concrete demarcation between user preferences and user redshifting data.\\



The code base for the developed software, named \marz{}, is hosted publicly on GitHub\footnote{\url{https://github.com/Samreay/Marz}}, allowing for open issue management, feature requests, open collaboration, forking of the project and instant web-hosting\footnote{\marz{} can be found at \url{http://samreay.github.io/Marz/}}.







\section{FITS file format}

In this section, we detail the FITS file format that can be consumed by \marz{}. The main data extraction algorithm works by searching for extension names. Spectrum intensity is expected to found in either the primary HDU or one named \textit{intensity}. Spectrum variance is searched for using the extension name \textit{variance}, and similarly the \textit{sky} and \textit{fibres} should contain the sky spectrum and details on the fibres respectively. Whilst spectra can be viewed with only the intensity present, the matching algorithms require variance as well. The sky and fibre data is optional. The intensity and variance data should be present as images of $m\times n$ dimensions, where $m$ is the number of pixels in the spectrum and $n$ are the number of spectra in the file. The sky spectrum can take on a similar $m\times n$ format, or simply be present in an array of length $m$, which loads the same sky spectrum for all spectra.\\

If the \textit{fibres} extension exists, it should be as a binary table of $n$ rows. \marz{} searches for the columns TYPE, NAME, RA, DEC, MAGNITUDE and COMMENT. Spectra marked with types other than `P' are removed from analysis, and spectra marked with the comment `PARKED' are also removed. Priors can be enforced by specifying an object type in the comment field, and the effect of object type per template can be modified in the \verb;templates.js;, where the property \verb;weights; is used to map object types to numeric weights.\\


\marz{} does not require each intensity value to have a specific wavelength. The wavelength of the input spectra are determined from the primary header, where the Angstrom wavelength \verb;CRVAL1; located at pixel \verb;CRPIX1; is used to calculate the wavelengths for all pixels, given a pixel wavelength separation given by either \verb;CDELT1; or \verb;CD1_1;. Support for log-linear wavelengths can be added on request. {\red I want to do this though}. The spectra is further assumed to have undergone heliocentric velocity correction and the wavelengths given are in air wavelengths and have not been vacuum shifted.\\

Example FITS files can be downloaded on the \textit{Usage} section of the \marz{} application.













\section{Matching Algorithm}

The algorithm that takes an observed spectrum and measures the redshift is the heart of any redshifting program. The matching algorithms in \marz{} utilise a modified version of the \autoz{} algorithm implemented by \citet{baldry2014galaxy}. In light of the success of $\chi^2$ algorithms in modern surveys \citep{bolton2012} an initial $\chi^2$ algorithm was developed, but was consistently outperformed by the cross correlation algorithm and discarded. FITS file input from the AAOmega spectrograph undergo two distinct steps of processing: (1) the preprocessing stage to clean the data and (2) the matching process to align the observed spectra with template spectra, simultaneously finding the best-fit object type and shifting it to the best-fit redshift.\\

The preprocessing stage is designed to remove any bad pixels and cosmic rays from the data before being returned back to the interface, so that the user can manually redshift using the cleaned data.
\begin{itemize}
\item \textbf{Bad pixels} are defined when the intensity spectrum is NaN, negative or exceeds a certain configurable threshold, or if the variance spectrum for the pixel is negative.
\item \textbf{Cosmic rays} are identified via second neighbouring pixels exceeding thirty standard deviations from the mean, with lower thresholds than $30\sigma$ often mistaking strong emission lines as cosmic rays. 
\end{itemize}
Bad pixels are replaced with a mean to four pixels either side of the pixel, and pixels flagged as a cosmic ray have four pixels to either side replaced by the mean of eight pixels to either side, discounting points in the cosmic ray. These values were the minimum window found to produce sufficient quality means and remove the majority of cosmic rays. Continuum is initially subtracted via the method of rejected polynomial subtraction, where a 6-degree polynomial is iteratively fitted to the spectrum and, as with \autoz{}, all points greater than 3.5 standard deviations from the mean are removed from the fitting process. As soon as an iteration discards no extra pixels, or after fifteen iterations (to ensure the final array of values is not excessively sparse), the loop is terminated and the final polynomial should closely follow the continuum, and is thus subtracted out. Figure \ref{fig:continuum} illustrates each step in this process.\\

This initial round of continuum subtraction is not intended to be high enough quality for the automatic matching process, it is done to give the user the option of manually redshifting spectra without continuum, allowing them to focus on the emission and absorption features of the spectrum without the broad shape of the continuum to distract. In order to limit the effect singular emission features can have on spectrum matching, all features are clipped at a distance of 30 standard deviations from the mean. Unlike many redshifting programs, heliocentric corrections are not applied to the spectra as they are expected to have been applied already in the given spectra. This is in light of the high amount of stacking done in the OzDES team, where spectra from different observation runs are stacked together to increase the signal-to-noise ratio. As these observations are generally on different nights and during different times in the night, each of them should have its own heliocentric correction applied before being stacked, and as such the spectra given to \marz{} are assumed to have come through a data pipeline which includes heliocentric correction.\\


\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{continuum.pdf}
\caption{The top subfigure shows an example input spectrum to the continuum removal process. The sixth degree fitted polynomial is shown dashed in this subplot, and the spectrum after subtraction of this polynomial fit is shown in the middle subplot, where we can see that broad continuum features are removed. The middle subplot also shows the output of the smoothed median filtering (dashed), and spectrum after subtraction of this filter is shown in the bottom subplot, where we can see even fine continuum detail has been removed from the spectrum.}
\label{fig:continuum}
\end{figure*}

\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{quasarProcess.pdf}
\caption{The quasar processing steps illustrated. The top panel depicts in input spectrum intensity, with variance shown in red. The polynomial subtraction removes the almost constant continuum and is shown in the second panel from the top. The third panel shows the output after several steps, including an initial tapering of the spectrum, rolling point mean of the spectrum. The variance undergoes median filtering, boxcar smoothing and addition of minimal variance as described in text. The final spectrum after dividing the intensity by the variance is shown in the bottom panel. We can see that the spectrum is cleaner, is properly tapered, and emission features are accentuated.}
\label{fig:quasarProcess}
\end{figure*}







The matching process, which takes the output of the preprocessing step in the form of an intensity and variance spectrum, where the variance spectrum is computed in the data pipeline using standard Poison and readout noise. \marz{} first duplicates the intensity spectrum so that two copies exist internally. This is necessary because the matching of the broad-featured quasar template differs to matching of the other templates, and the copy of the intensity spectrum used for quasar matching shall now be referred to as the quasar spectrum, and the other spectrum - used to match all other templates, shall be referred to as the general spectrum.

Departing from the \autoz{} algorithm, the quasar spectrum undergoes smoothing via a rolling-point exponential decay mean function of window width 7 pixels, with exponential decay factor of $0.9$, such that each points becomes
\begin{align}
x_i = \left( \sum_{k = -3}^3 0.9^{|k|}   \right)^{-1} \sum_{j = -3}^3 x_{i+j} 0.9^{|j|},
\end{align}
where both the size of the window and strength of the exponential decay are not sensitive to small change. This method of smoothing was selected and tuned so that the location of broad peaks remained unchanged whilst still providing sufficient smoothing of the spectrum to increase similarity to the template.\\

As the sharp features of the general templates are not improved by smoothing, the general spectrum instead undergoes a second step of continuum subtraction, where a boxcar smoothed median filter (121 pixel window of boxcar smoothing and 51 pixel window median filter) is subtracted from the spectrum, with pixel values following \autoz{} and corresponding to a wavelength distance of 125 and 53 Angstroms respectively for typical AAOmega spectra. This step is not applied to the quasar spectrum, as the fineness of the smoothed median subtraction would result in broad features being completely removed from the spectrum. \\

The general spectrum then has error adjustment applied, where each pixel has its variance set to the maximal value of itself and the variance of its two neighbouring pixels. Following \citet{baldry2014galaxy}, this is to allow for uncertainty in the sky subtraction and any underestimation of errors next to sky lines. The variance spectrum is then widened again, where each pixel is set to a maximum of its original value or 70\% of a thirteen pixel median filter of width 13 pixels, which serves to remove from the variance any points of sufficiently low variance that division of the intensity by the variance would create a fake emission feature. Numerical values chosen mirror those used in the GAMA survey. The intensity of the general spectrum is divided by the variance spectrum to down-weight pixels with higher uncertainty. As we wish to preserve broad features found in quasar spectra, we require the quasar error spectrum to be sufficiently smooth that broad features are not destroyed when we apply the variance onto the spectrum intensity. A median filter of 81 pixel width is applied to the variance, and then the result is smoothed with boxcar smoothing using a window of 25 pixels, where the pixel window widths used are not sensitive to change so long as fine pixel detail is removed from the variance plot. In order to preserve even more broad shape by creating a more uniform variance that does not have the possibility of creating false features by having small variance, the variance of the spectrum is increased by addition of five times the minimum spectrum variance, where again the amount of variance to add is not highly sensitive. The quasar intensity is then divided by the adjusted variance to product a spectrum that retains broad features and shapes, but down weights sections of higher variance which are commonly observed at wavelengths close the end of spectroscopic CCD range. The loss of resolution entailed by the variance modifications detailed above results in any sharp emission lines present in the spectrum to be more significant when compared to emission lines in the general spectrum, however the relative lack of sharp emission line features in the quasar template makes this issue not significant.\\








Both the general and the quasar spectrum undergo cosine tapering and root-mean-square normalisation, the former to remove ringing in a Fourier transform \citep[apodization;][]{kurtz1998rvsao}, with pixel width following \autoz{} but insensitive to change, and the latter to ensure comparable cross correlation values between different templates. The spectra are oversampled and then Fourier transformed. The quasar spectrum's transformation is then cross correlated with the quasar template, and all other templates are cross correlated with the general spectrum. Cross correlation results are then inverse transformed, with the inverse transformed array representing cross correlation strength over a redshift range. Peaks within allowed redshift ranges for each template are selected, and if prior information on the object type is accessible in the FITS file, the peaks for each template are then weighted. Peaks from all templates are then sorted together, and the ten highest correlation value peaks have a quadratic fit applied around the peak for sub-pixel determination of local maxima. The sub-pixel location of the peaks are converted into a redshift value, and these are returned to the user, with the highest peak representing the best automatic matching found. A potential quality is returned to the user, which is a function of the cross correlation strength of the two greatest peaks, $v_1$ and $v_2$ respectively. These peak values are used to construct a Figure of Merit (FOM) that takes the functional form
\begin{align}
{\rm FOM} &= (v_1-\alpha)^{\beta} \times \frac{v_1}{v_2}. \label{eq:autoqop}
\end{align}
The values for $\alpha$, $\beta$ and the FOM cut offs shown in \eqref{eq:autoqop2} were informed off a likelihood distribution created to minimise the weighted number of misclassification, where a misclassified QOP4 spectra (99\% confidence) was weighted ten times as much as a misclassified QOP3 spectra (90\% confidence), and so on for QOP2 spectra (50\% confidence) and QOP1 (no confidence). Parameters $\alpha$, $\beta$ and the FOM cutoff for each QOP were set as free variables in a Markov Chain Monte Carlo simulation, and the approximate maximum likelihood of the marginalised distributions were selected as final values, such that $\alpha = 2.5$, $\beta = 0.75$ and the FOM boundaries are as given in \eqref{eq:autoqop2}.
\begin{align}
{\rm FOM} &= (v_1-2.5)^{0.75} \times \frac{v_1}{v_2} \label{eq:autoqop3}\\
{\rm QOP} &= \begin{cases}6 & \text{if } {\rm FOM} > 4.5 \text{ and fit to a stellar template} \label{eq:autoqop2}\\
4 & \text{if } {\rm FOM} > 8.5  \\
3 & \text{if } {\rm FOM} > 4.5 \\
2 & \text{if } {\rm FOM} > 3 \\
1 & \text{otherwise} \end{cases}
\end{align}
This suggested QOP is not meant to replace human quality flags, but simply give the redshifter an estimate of spectrum quality before and during manual verification of the automatic result. The probability of agreement with a human redshifter is illustrated in Figure \ref{fig:autoqop}. The suggested QOP is computed from first calculating a Figure of Merit (FOM) from the cross correlation results.

\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{autoqop.pdf}
\caption{The probability of \marz{} assigning a suggested quality differentiated by the quality assigned by a human redshifter. Importantly, a QOP1 spectra and a QOP2 spectra respectively have a 0.8\%  and 1.4\% chance of being classified as a QOP4 spectra. However, these mismatches are primarily due to errors in the data reduction process which introduce false features. From the data analysed, 37\% of actual QOP4 spectra are classified as QOP3, where the automatic QOP algorithm has assigned a lower value due to the presence of a strong secondary peak in the cross correlation values, an occurrence illustrated in Figure \ref{fig:xcors}.}
\label{fig:autoqop}
\end{figure}


\begin{figure*}[t]
\centering
\includegraphics[width=\textwidth]{xcors.pdf}
\caption{A high quality emission line galaxy spectrum matched against the High Redshift Star Forming Galaxy template. The two strongest cross correlation peaks and the corresponding redshifted template have been displayed beneath the original spectrum for illustrative purposes.}
\label{fig:xcors}
\end{figure*}








\section{Template Selection}



\begin{figure*}[h]
\centering
\includegraphics[width=\textwidth]{templates.pdf}
\caption{A visual display of the twelve templates currently in \marz{}, displayed after continuum subtraction.}
\label{fig:templates}
\end{figure*}


It is common in automated matching systems for a large number of templates to be used compared to input spectra. The templates found in \marz{} were sourced from original templates from 2dF \citep{colless2001}, WiggleZ \citep{Drinkwater21012010}, the Gemini Deep Deep Survey \citet{abraham2004}, and \autoz{} \citep{baldry2014galaxy}, where the templates in \autoz{} used consist of galaxy eigenspectra from \citet{bolton2012} and stellar spectra from SDSS DR2 \citep{SubbaRao2002}. These templates were sorted, compared, and a selection of twelve representative templates were extracted, consisting of five stellar templates, 1 AGN template and 6 galactic templates. Inclusion of a greater number of templates was not found to have a minimal impact on matching performance. Whilst extra target types can be added in the future, there are three challenges for \marz{} when attempting to handle a large number of templates. Firstly, users desired to be able to fully replicate the matching capacity of the automatic system when manually redshifting, and a large number of templates complicates the user interface and slows down the process of the user assigning an object type to the spectrum. It would be possible to only display to the user a restricted set of templates, however user feedback indicated this was an undesired solution. Due to the interpreted nature of Javascript and its lack of vector processing capability, computational performance is roughly an order of magnitude worse than on typical compiled code. As the computation time for each spectrum was roughly proportional to the number of templates to match, the number of templates was also kept relatively small to ensure that the automatic matching performance was still acceptable on low-end machines. The final concern when adding more templates is the download size of the web application, such that the size of the template dependency remains small enough to be easily redownloaded on page refresh. A potential solution to this is to enable javascript caching of the template file, such that it only needs to be downloaded once.


\clearpage

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{2dfComp.pdf}
\caption{A comparison of matching efficiency using high signal-to-noise data from the 2dFLenS survey and a matching threshold of $\Delta \log(1+z) \leq 0.0015$, corresponding to a velocity difference of  $450$ km/s. 2217 QOP4 spectra from ten fields are compared in this plot. The vertical axes shows the redshift assigned by an experienced redshifter, and is taken to be correct in this comparison. The horizontal axes show the automatic results of the four algorithms being compared: the \runz{} cross correlation algorithm, the \runz{} emission line matching algorithm, \autoz{} and \marz{}. The total accuracy of the algorithms is detailed in the legend. The success rate for each algorithm is shown in the top right of each subplot. The \marz{} algorithm and \autoz{} offer comparable accuracy for high redshift spectra, with \autoz{} pulling ahead slightly due to an increased number of templates being used in the matching process.}
\label{fig:high}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=\columnwidth]{run009Comp.pdf}
\caption{Low signal-to-noise, high-redshift data from the OzDES survey is used in this comparison of matching capability, where two spectra agree if their recession velocity is within 450 km/s of each other for standard galactic templates, or within 900 km/s of each other for AGN spectra. Respectively this corresponds to $\Delta \log(1+z) < 0.0015$ and $\Delta \log(1+z) < 0.003$. AGN matches are shown with the $+$ symbol, with other objects shown with a dot. Overall success rates are shown in the top right hand corner of each subplot. 1083 spectra from eight fields with a redshift range of up to 4.55 are used in this comparison. \runz{} emission line matching performs the worst, with strong diagonal lines of non-unity slope showing repeated spectra feature misidentification. Vertical banding in the \runz{} cross correlation algorithm significantly impacts its effectiveness, and \autoz{}'s lack of high redshift templates and hard-coded $z=0.9$ cutoff make the comparison almost inapplicable. Here the quasar specific matching algorithm used by \marz{} stands out, giving a success rate of over 90\% for the OzDES spectra.}
\label{fig:low}
\end{figure}
















\section{Matching Performance}

Performance testing for \marz{} was conducted by looking at two sets of distinct data - one from the OzDES team with low signal-to-noise data at high redshift, and one from the 2dFLenS team with medium signal-to-noise data. In both cases, manual redshifting was performed by experienced redshifters in \runz{}, and the automatic matches produced by \runz{} and the automatic results returned by \marz{} were compared to the manually assigned redshift for all results assigned a QOP of 4 (99\% confidence interval). Comparisons were also made with the \autoz{} program, which is the software being used for the GAMA survey and also being adopted by the 2dFLenS team. These surveys have a smaller number of object types and smaller redshift ranges than OzDES, and therefore have simpler requirements for the redshifting software. These high and low signal-to-noise results are shown in Figures \ref{fig:high} and \ref{fig:low}. The redshifting accuracy of \marz{} for high signal-to-noise data gave the correct redshift for 97.4\% of QOP4 spectra, a failure rate far less than that offered by \runz{} and comparable to \autoz{}. For the low signal-to-noise (high redshift) OzDES data, the accuracy of \marz{} was $\approx 92$\%. This is in comparison to the best \runz{} algorithm giving a total accuracy of 54.6\%. The lower success rate of \autoz, 48.0\%, is because the redshift ranges and object types found in the OzDES data are outside the matching capacity of the program.\\

In addition to the QOP4 successful recovery rates, a normalised probability distribution describing the likelihood for spectral line misclassification can been produced. This has been done for QOP 4 and QOP 3 (90\% confidence) results, in Figure \ref{fig:f4}. Commonly misidentified spectral lines are labeled in the figure, and can be seen to be a primary source of misclassification across all algorithms. The common [O$_{\mathrm{II}}$]/[O$_{\mathrm{III}}$] misclassification is strongly present in the \marz{} failure rates, however its significance drops to approximately 10\% of the total failure rate when only QOP4 misclassifications are considered, with the majority of the total failure rate of 4.1\% centered around 1. Whilst the expected failure rate for QOP 3 redshifts is ten times higher than for QOP 4 values, this still warrants extra investigation into whether this is a deficiency in the matching algorithm or an effect of the reluctance of human redshifters to assign a QOP 4 quality to spectra matching only on the singular O$_{\rm{II}}$ feature. If there is an algorithmic deficiency, down weighting of high redshift O$_{\rm{II}}$ matches could be implemented to reduce the misclassification rate. Commonly misclassified features are also visible on Figure \ref{fig:high} and \ref{fig:low} as linear relationships off the diagonal.\\








\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{errorRateqop3.pdf}
\caption{The percentage chance, per successfully assigned redshift of quality 3 or 4, of assigning an automatic redshift $z_A$ categorised as a catastrophic failure with respect to correct manual redshift $z_M$. A catastrophic failure, here defined as $\Delta \log(1 + z) > 0.0075$, corresponds to a velocity difference of $2\,250$ km/s and generally indicates misclassified features in the spectra. For an analysis of non-catastrophic failures, see Figure \ref{fig:systematic}. Peaks in the probability distribution generally represent misidentified spectral lines, and common misidentification ratios have had the corresponding spectral lines labelled, such that the first label, MgII/H$\alpha$ represents the MgII feature misidentified as H$\alpha$ instead. Performance for \runz{} cross correlation, \runz{} emission line matching, \autoz{} and \marz{} are shown in their own panel. Panel probability axes are not to scale with one another, and the area covered represents the total failure rate. The 2dFLenS and OzDES data from Figures \ref{fig:low} and \ref{fig:high} are combined in this analysis, and QOP3 spectra (90\% confidence interval) have been included to give a greater number of sample points. The total failure rates are given as follows: \runz{} cross correlation: 42.4\%, \runz{} emission line matching: 55.1\% failure rate, \autoz{}: 42.1\% failure rate, \marz{}: 2.6\% failure rate.}
\label{fig:f4}
\end{figure}


\begin{figure}[h]
\centering
\includegraphics[width=\columnwidth]{systematic.pdf}
\caption{Systematic redshift offsets were investigated by examining the difference between manual redshifting (using the \runz{} cross correlation algorithm as the base) and the automatic results of redshifting algorithms. QOP4 spectra from OzDES and 2dFLenS were combined to give over three thousand secure manual redshifts, with the redshift distribution shown particulary for \marz{} and \autoz{}. The mean offset and median for both algorithms is to the order of $10^{-5}$ or less, with the redshift variance on order $10^{-4}$. The redshift mean and median values are small enough to be indicative that no systematic offset in redshift would be generated by utilising either algorithm.}
\label{fig:systematic}
\end{figure}

















\section{Interactive Interface}

The interactive interface consists currently five primary screens: the overview, detailed, templates, settings, and usage screen. The first two screens - the overview and detailed screens, are where users will spend the vast majority of their time, and thus screenshots of them have been provided in Figures \ref{fig:overview} and \ref{fig:detailed}. The overview screen provides users with a high level view of the spectra in the loaded FITS file, detailing what they have been matched to and the quality assigned to the matches. Filtering for this screen allows users to sort results or to filter by categories, for example only displaying matches of quality (QOP) 4 or all matches to quasar templates. Comma-separated variable (CSV) output in the form of previously downloaded \marz{} results files can be loaded into the program in the same drag-and-drop manner as FITS files, allowing easy verification of redshift results by different users on different machines. A progress bar at the top of the screen keep track of current file completion and file quality.\\



\begin{figure*}[H]
\centering
\includegraphics[width=\textwidth]{InterfaceZ.png}
\caption{The overview screen, showing data from a FITS file courtesy of Chris Blake and the 2dFLenS survey. Users can switch between a sortable tabular view and a graphic tile view, filter on object types, redshift ranges, templates and QOP values. The top of the screen shows the navigation menu, file completion progress bar and input for user initials. Visible at the bottom of the screen is the application footer, which shows the program's progress through automatic matching (automatically matched templates are shown in red in the graphical tiles). The bar changes colour depending on progress - green for preprocessing, red for matching and blue for completed. During the first two stages, a pause button is available to the user. If any results exist, a download button is available, which saves the current results to the file system.}
\label{fig:overview}
\end{figure*}

\begin{figure*}[H]
\centering
\includegraphics[width=\textwidth]{InterfaceZ2.png}
\caption{The detailed matching screen, showing spectrum 7 seen in the Overview screen in Figure \ref{fig:overview}. The menus at the top of the page allow the user to toggle data on or off (variance, sky spectrum, templates and whether to use the raw data or processed data). The menu bar also allows the user to reset to automatic or manual results, smooth the data, select which template to compare against, toggle between the best five automatic results, change the visual offset of the template and manually set the displayed redshift. The user can mark spectral lines by selecting a feature in the plot (either in the main plot or in any callout window) and then select the desired transition (either via keyboard shortcut or by selecting an option in the bottom row of the menu). Users can also change redshift by clicking on peaks in the cross correlation graph found between the spectra plot and the menu bars. Quality values for redshifts can also be assigned via keyboard shortcuts or via the vertical button menu on the left, and assigning a quality saves the result in the background and moves to the next spectrum. In the case where the ``QOP 0 only" option is selected in the left hand bar, the user is taken to the next spectrum without a quality flag set, or else it simply takes them to the next spectrum ordered by ID.}
\label{fig:detailed}
\end{figure*}

The detailed screen allows for better verification of automatic matches and also offers the possibility of manually redshifting spectra. Verification of the on screen displayed redshift is done simply by assigning a QOP value, and the top five automatic matches can be cycled if the best match is visibly incorrect. Keyboard shortcuts are available for almost all actions, where key mappings are based off the shortcuts available in \runz{} in order to make transitioning from \runz{} to the \marz{} as easy as possible. Users can click on features in the detailed plot and then mark them as spectral lines. Matches can be updated by by automatically fitting to the best cross correlation peak value within a small deviation window. The user can also toggle whether to the display the raw data or the preprocessed data, whether to render a template under the data plot, and whether to display continuum or not. Boxcar smoothing is available to help spectrum legibility.\\

The templates screen is mostly non-interactive, and simply displays all the templates used by the system with the option to enable or disable specific templates at will. The settings screen gives options to explicitly set how many processing threads to create, whether results should be saved in the background, and offers the ability to clear all saved results in the system, or to simply clear results for the currently loaded FITS. The usage page gives instructions on how to use the program, an explanation of the purpose of each screen, how to raise issues or feature requests via GitHub, and provides several example FITS files for users who simply want to test out the system without having to source a FITS file themselves. It also provides a list of keyboard shortcuts for those users whom are not familiar with \runz{}.

Two main error safeguards have been implemented in the program to stop unnecessary loss of work. The first is a confirmation request when attempting to close down the application, which solves the issue of closing the whole browser with an open tab of \marz{}. The second and more robust solution is to use the local storage capacity available in modern browsers to save results in the background after every automatic or manual redshift is assigned. This allows users to close the program, and resume where they left off simply by dragging the original FITS file back into the application.













\section{Conclusion}

Overall, it can be seen that for both high and low signal-to-noise data, \marz{} outperforms \runz{} on automatic matching of spectra. \marz{} also provides an enhanced and more intuitive user experience, and the web-based nature of the application means that installation and updating are now no longer of any concern at all. As such, \marz{} presents a strong alternative to the \runz{} application, and a large step forward in the demonstration of web frameworks as a platform for non-intensive computational analysis. As \marz{} simply requires generic FITS files to work, it has application for simple FITS file inspection or as a redshifting tool for other surveys.

\section*{Acknowledgements}
We would like to thank the OzDES and 2dFLenS teams for their feedback, input and user testing. The \marz{} template catalogue comes from the WiggleZ and SDSS template samples, and multiple external libraries have been utilised in the creation of this application: Google's AngularJS, Twitter's Bootstrap, AngularUI, Armit Kapadia's fitsjs, Corban Brook's Digital Signal Processing package, Eli Grey's FileSaver.js, Tom Alexander's regression.js package, lodash and jQuery. Parts of this research were conducted by the Australian Research Council Centre of Excellence for All-sky Astrophysics (CAASTRO), through project number CE110001020.


\bibliography{bibliography}


\end{document}

